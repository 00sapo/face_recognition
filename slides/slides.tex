\documentclass[unknownkeysallowed]{beamer}
\usetheme{metropolis}
\usepackage{textpos}
\usepackage{multirow}
\definecolor{dei}{RGB}{209, 0, 86}
\usepackage[utf8]{inputenc}

\title{Face recognition through RGB-D images and matrices of SVMs} % Article title
\subtitle{Based on Hayat et al., 2016}
\date{\today}
\author{Federico Simonetta, matricola 1129912 \\ Alberto Cenzato, matricola 1134707 }
\setbeamercolor{title separator}{fg=dei}
\setbeamercolor{progress bar}{fg=dei}

\begin{document}
\titlegraphic{\vspace{4.3cm}
	\hspace{8.5cm}
	\includegraphics[width=1.5cm]{unipd}

	\hspace{8.5cm}
	\includegraphics[width=2cm]{dei-logo}
}
\maketitle
\addtobeamertemplate{frametitle}{}{\begin{textblock*}{100mm}(.85\textwidth,-1cm)
		\includegraphics[height=1cm,width=2cm]{dei-logo}
	\end{textblock*}
}

\setbeamertemplate{section in toc}{\textbullet\ \normalsize \inserttocsection \\}
\setbeamertemplate{subsection in toc}{\-\hspace{2em}\textbullet\ \scriptsize \inserttocsubsection \\ }
\begin{frame}{Overview}
	\vspace*{6mm}
	\tableofcontents[section, subsections]
\end{frame}

\section{Hayat et al., 2016: \textit{An RGB-D based image set classification
for robust face recognition from Kinect data}}
\begin{frame}{Purpose of the algorithm}
	\begin{itemize}
		\item Purpose of the proposed algorithm is to recognize a person
			given an image set of that person in different poses
		\item This is useful especially for face recognition in video
			recording
		\item The algorithm takes advantage of depth info captured
			through Kinect cameras
	\end{itemize}

\end{frame}
\subsection{Preprocessing}
\begin{frame}{Preprocessing}
	\begin{itemize}
		\item An important step is the image preprocessing
		\item First of all, a simple \textit{k}-means clustering algorithm is executed on depth images to remove background
		\item Next, a precise cropping can be made, using pose informations computed on depth images
		\item Pose info are used to adjust face cropping window sizes
		\item Lastly, RGB images are converted to grayscale
	\end{itemize}
\end{frame}

\subsection{Image sets representation}
\begin{frame}{Image sets representation}
	\begin{itemize}
		\item Authors use face poses to discover 3 different clusters for each original image set
		\item They represent each of these clusters with a $16 \times 16$ covariance matrix computed through LBP features vectors
			\begin{itemize}
				\item Each image is subdivided in 16 blocks of equal size through a $4 \times 4$ grid
				\item On each block a LBP feature vector is computed
				\item Each entry of the covariance is computed on all the LBP of the same block of the person in the same pose:
					$$
					C_{p, q} = \frac{1}{n} \sum_{i=1}^n
					y(p, i)y(q, i)
					$$
				where $y(k, j)$ is the difference of each $k^{th}$ LBP vector from its own mean
			\end{itemize}
	\end{itemize}
\end{frame}

\subsection{SVMs training and prediction}
\begin{frame}{Training}
	\begin{itemize}
		\item Authors are not very clear in the training description
		\item They used Stein function as kernel for a vector of SVMs
		\item Each SVM is charged of recognizing one person in one of the three poses
		\item For each person in each pose, two SVMs exist, one for RGB	images and one for depth images
		\item Stein kernel is defined by this equation:
			$$
			k(X, Y) = e^{\sigma S(X,Y)}
			$$
			where
			$$
			S(X, Y) = \log\det\left(\frac{X +
			Y}{2}\right)-\frac{1}{2} \log \det(X\times Y)
			$$
		\item They also tested \textit{k}-fold testing showing that	results decrease increasing $k$

	\end{itemize}
\end{frame}

\begin{frame}{Prediction}
	\begin{itemize}
		\item A query is composed by a set of images that are preprocessed and clusterized in three sets based on estimated poses
		\item On each subset the covariance matrix is computed and is given in input to each SVM model
		\item Each of the three covariance matrices of the query will receive $6 \times n$ votes, where $n$ is the number of SVMs training sets
		\item The one that will receive the maximum number of votes	will be predicted as the recognized face
		\item If no SVM will recognize it, it will be labeled as `unknown'
	\end{itemize}
\end{frame}

\section{Datasets}
\begin{frame}{Datasets}
	\begin{itemize}
		\item The project assignment was to test the proposed algorithm	on a new small dataset containing 338 images of 26 people, with different lightings conditions and background scenes
		\item This was unsuccessful, therefore, after many attempts, we	changed the dataset to a subset of the dataset used by the authors
		\item This new dataset contains more than 15.000 RGB-D images with 24 different images sets of 20 different peoples
	\end{itemize}
\end{frame}

\section{Our implementation}
\subsection{Preprocessing tweaks}
\begin{frame}{Preprocessing tweaks (1)}
	Very poor results on the first small dataset forced us to implement some changes to the preprocessing algorithm
	\begin{itemize}
		\item \textit{Face-detection-first}: we used Haar cascade classifiers made available in OpenCV to detect a face, crop it and then segment background and refine	cropping; if no face was detected, we used a fixed threshold segmentation
		\item \textit{Outlier removal}: we first computed the maximum-area connected component and crop it with approximating it to its bounding box; this improved clustering
		\item \textit{Histograms segmentation}: we tried to segment the	histogram region containing the highest peak and if face detection or pose estimation failed we retried	with the region containing the second higher peak. We abandoned it because it was too slow (but nice precision)
	\end{itemize}
\end{frame}

\begin{frame}{Preprocessing tweaks (2)}
	\begin{itemize}
		\item \textit{Adjusted face cropping}:
			\begin{itemize}
				\item G. Fanelli et al. (2011) algorithm to	compute face detection and pose estimation
				\item We changed parameters for face cropping
				\item Corrected ROI position along the X axis
			\end{itemize}
		\item \textit{Removed rotation matrix}: pose clustering	directly on Euler angles: rotation matrix computing enlarged eventual pose detection errors
	\end{itemize}
\end{frame}

\subsection{Training strategies}
\begin{frame}{Training strategies}
	The paper was unclear about the training strategy. Because of this, we tried four different training algorithms:
	\begin{enumerate}
		\item All covariance matrices but one had negative labels
		\item All SVMs of the same correct identity	had positive label (very bad results)
		\item Covariance matrices of the correct identity but of different poses were removed from the training set of	each SVM (only on the first dataset)
		\item \textit{Leave-one-out}: without success; authors say that \textit{k-fold} cross validation gave low results (only on the first dataset)
	\end{enumerate}
\end{frame}

\begin{frame}{Training strategies}
	\includegraphics[width=\linewidth]{svms}
\end{frame}

\subsection{Prediction}
\begin{frame}{Prediction}
	\begin{itemize}
		\item We noted that some identity received too many votes
		\item We introduced a new prediction rule: if an identity has more than $t$ candidates with the maximum number of votes, it is forced to `unknown'
		\item At first, $t=k \times c$, where:
			\begin{itemize}
				\item $k=1$ if only RGB or only depth is used
				\item $k=2$ if they are used together
				\item $c$ is the number of pose subsets
			\end{itemize}
			In fact, $k \times c$ is the maximum number of votes that an identity should receive.
		\item From experiments we found that using RGB images only,	\textit{FP-unknown} was always 0. We changed the rule so that it took in account only RGB images; consequently, $t = c$

	\end{itemize}
\end{frame}

\section{Technical issues}
\subsection{Computational issues}
\begin{frame}{Computational issues}
	\begin{itemize}
		\item Preprocessing is really slow, especially the covariance computation
		\item We implemented multithread version but not GPU support
		\item Using Intel i7-4510HQ CPU, (4 cores, 2 threads per core, 2.5 GHz frequency, boosted to 3.5 GHz), preprocessing	and covariance computing of all the dataset takes less than	10 minutes
		\item There is no particular issue on RAM usage, it is needed about 1GB during preprocessing. This is due to the covariance computing which need all images of an identity in RAM: fewer images per identity would need less RAM
	\end{itemize}
\end{frame}

\subsection{Implementation issues}
\begin{frame}{Implementation issues}
	\begin{itemize}
		\item Code for pose estimation needed depth images represented in OpenCV \textit{Mat} objects
		\item We had to switch completely to OpenCV
		\item Other issues were found in the use of machine learning module of OpenCV, namely
			\begin{itemize}
				\item in kmeans algorithm
				\item in loading and saving from file of custom	kernel SVMs
			\end{itemize}
	\end{itemize}
\end{frame}

\section{Evaluation}
\subsection{Description of the experiments}
\begin{frame}{Description of the experiments}
	We performed many experiments, with different combination of `known'-`unknown' ids. Every one was set up in this way:
	\begin{itemize}
		\item 40 images per person were randomly removed and used as testing set. Each query was made by a set of 40 images
		\item 5 identities chosen randomly were completely removed from the training set to simulate the `unknown' behavior
		\item People who had two recordings were never removed
		\item $\frac{1}{3}$ of each sequence of the training set was used as validation set to evaluate SVMs during parameters optimization
	\end{itemize}
\end{frame}

\subsection{Discussion and results}
\begin{frame}{Evaluation measures}
	We computed results in terms of:
	\begin{itemize}
		\item \textit{rank-1}: ratio between correct recognitions and total number of sets in the query, where `unknown' identities are considered correct if detected as	`unknown'
		\item \textit{FP-unknown}: ratio between incorrect recognition of `unknown' persons and the total number of `unknown' persons
	\end{itemize}
\end{frame}

\begin{frame}{Discussion}
	\begin{itemize}
		\item Our results are comparable to the ones of the authors, taking into account the smaller size of our	dataset
		\item Despite the smaller sizes, the second dataset we used had a very larger mean number of images per identity (about 700 images) with respect to the dataset used by the authors (about 300 images per identity)
		\item This let us argue that the major contribute to performance is not given by the total number of images, but by the number of identities
		\item Our results with only RGB or D images are much lower than	those claimed by authors
	\end{itemize}
\end{frame}

\begin{frame}{Results (1)}
	\scriptsize
	\begin{table}[]
		\centering
		\caption{Results with first version of the prediction rule}
		\begin{tabular}{|l|l|c|l|c|l|c|}
			\hline
			\multirow{2}{*}{\bf Removed ids} & \multicolumn{2}{c|}{Using RGB-D} &\multicolumn{2}{c|}{Using RGB only} &\multicolumn{2}{c|}{Using D only} \\ \cline{2-7}
							 & \bf Rank-1 & \bf FP-unk          & \bf Rank-1 & \bf FP-unk            & \bf Rank-1 & \bf FP-unk  \\ \hline
			04, 06, 10, 11, 19               & 0.83	      & 0.4                 & 0.29       & 0.0                         & 0.33       & 0.4\\ \hline
			06, 10, 19, 20, 24               & 0.87	      & 0.0                 & 0.33       & 0.0                         & 0.50       & 0.0\\ \hline
			08, 09, 14, 17, 24               & 0.79	      & 0.4                 & 0.375      & 0.0                         & 0.33       & 0.2\\ \hline
			01, 16, 17, 19, 24               & 0.92	      & 0.2                 & 0.375      & 0.0                         & 0.42       & 0.2\\ \hline
			01, 09, 12, 16, 19               & 0.83	      & 0.6                 & 0.25       & 0.0                         & 0.375      & 0.4\\ \hline
			09, 10, 16, 19, 24               & 0.67	      & 0.8                 & 0.29       & 0.0                         & 0.125      & 0.8\\ \hline
			04, 09, 10, 11, 16               & 0.92	      & 0.2                 & 0.375      & 0.0                         & 0.33       & 0.2\\ \hline
			01, 08, 09, 10, 19               & 0.50	      & 0.8                 & 0.375      & 0.0                         & 0.125      & 0.6\\ \hline
			04, 10, 11, 13, 24               & 0.54	      & 1.0                 & 0.375      & 0.0                         & 0.20       & 0.0\\ \hline
			08, 14, 17, 23, 24               & 0.75	      & 0.6                 & 0.375      & 0.0                         & 0.29       & 0.6\\ \hline
			\bf mean                         & \bf 0.76   & \bf 0.5             & \bf 0.3785 & \bf 0.0                     & \bf 0.33   & \bf 0.34\\ \hline
		\end{tabular}
	\end{table}


\end{frame}

\begin{frame}{Results (2)}
	\scriptsize
	\begin{table}[]
		\centering
		\caption{Results with second version of the prediction rule}
		\begin{tabular}{|l|l|c|l|c|l|c|}
			\hline
			\multirow{2}{*}{\bf Removed ids} & \multicolumn{2}{c|}{Using RGB-D} &\multicolumn{2}{c|}{Using RGB only} &\multicolumn{2}{c|}{Using D only} \\ \cline{2-7}
							 & \bf Rank-1 & \bf FP-unk          & \bf Rank-1 & \bf FP-unk            & \bf Rank-1 & \bf FP-unk  \\ \hline

			06, 09, 13, 17, 24               & 1.0        & 0.0                 & 0.33       & 0.0                   & 0.375      & 0.0\\ \hline
			06, 10, 11, 17, 20               & 0.92       & 0.0                 & 0.42       & 0.0                   & 0.54       & 0.0\\ \hline
			01, 09, 13, 14, 19               & 0.875      & 0.0                 & 0.42       & 0.0                   & 0.33       & 0.2\\ \hline
			04, 06, 11, 16, 17               & 0.79       & 0.0                 & 0.42       & 0.0                   & 0.42       & 0.2\\ \hline
			04, 11, 12, 17, 20               & 0.79       & 0.0                 & 0.29       & 0.0                   & 0.125      & 0.8\\ \hline
			04, 11, 12, 16, 23               & 0.71       & 0.0                 & 0.33       & 0.0                   & 0.08       & 1.0\\ \hline
			01, 06, 10, 17, 20               & 0.875      & 0.0                 & 0.375      & 0.0                   & 0.21       & 1.0\\ \hline
			10, 14, 16, 20, 24               & 0.92       & 0.0                 & 0.25       & 0.0                   & 0.375      & 0.0\\ \hline
			04, 06, 08, 14, 23               & 0.67       & 0.0                 & 0.33       & 0.0                   & 0.08       & 1.0\\ \hline
			04, 08, 11, 16, 20               & 0.92       & 0.0                 & 0.375      & 0.0                   & 0.08       & 1.0\\ \hline
			\bf mean                         & \bf 0.85   & \bf 0.0             & \bf 0.354  & \bf 0.0               & \bf 0.2615 & \bf 0.52\\ \hline
		\end{tabular}
	\end{table}


\end{frame}
\section{Future Development}
\begin{frame}{Future Development}
	\begin{itemize}
		\item Computational optimization
			\begin{itemize}
				\item training and prediction not in multithreading
				\item GPU (CUDA?)
			\end{itemize}
		\item SVMs saving and loading to file
		\item In depth study of the gap in results relative to training	and prediction by using just RGB or just Depth
		\item Further exploring how results change when changing dataset:
			\begin{itemize}
				\item how useful the prediction rule is when using original author's dataset?
				\item are results still high by using few images per identity and many different identities (enterprise context)?
			\end{itemize}
		\item Checking true positives of `unknown' predictions

	\end{itemize}
\end{frame}

\section*{Thank you for your kind attention}

\end{document}
